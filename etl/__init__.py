"""Helper utilities for the ETL pipeline."""

from .extract import (
    DEFAULT_FILE_ID,
    DEFAULT_RAW_PATH,
    build_download_url,
    download_csv_text,
    load_remote_csv,
    preview_dataframe,
    extract_dataset,
    save_raw_csv,
    validate_raw_dataframe,
)
from .transform import (
    DEFAULT_PARQUET_PATH,
    auto_convert_dataframe,
    auto_convert_source_dataset,
    save_dataframe_to_parquet,
)
from .load import (
    DEFAULT_CREDS_DB,
    DEFAULT_CREDS_TABLE,
    DEFAULT_DATABASE,
    DEFAULT_PARQUET_PATH as WRITE_PARQUET_PATH,
    DEFAULT_SCHEMA,
    DEFAULT_TARGET_TABLE,
    DbCredentials,
    check_sqlite_integrity,
    create_postgres_engine,
    describe_sqlite_table,
    load_credentials_from_sqlite,
    load_parquet_dataset,
    preview_inserted_rows,
    run_upload_workflow,
    write_dataframe_to_postgres,
)
from .main import main as cli_main, run_pipeline

__all__ = [
    "DEFAULT_FILE_ID",
    "DEFAULT_RAW_PATH",
    "DEFAULT_PARQUET_PATH",
    "DEFAULT_CREDS_DB",
    "DEFAULT_CREDS_TABLE",
    "DEFAULT_DATABASE",
    "DEFAULT_TARGET_TABLE",
    "DEFAULT_SCHEMA",
    "WRITE_PARQUET_PATH",
    "DbCredentials",
    "build_download_url",
    "download_csv_text",
    "load_remote_csv",
    "extract_dataset",
    "preview_dataframe",
    "save_raw_csv",
    "validate_raw_dataframe",
    "auto_convert_dataframe",
    "auto_convert_source_dataset",
    "save_dataframe_to_parquet",
    "check_sqlite_integrity",
    "describe_sqlite_table",
    "load_credentials_from_sqlite",
    "create_postgres_engine",
    "load_parquet_dataset",
    "write_dataframe_to_postgres",
    "preview_inserted_rows",
    "run_upload_workflow",
    "run_pipeline",
    "cli_main",
]
